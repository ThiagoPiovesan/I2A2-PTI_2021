{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este primeiro método de resolução, consiste na utilização de conceitos de NLP, e vetorização para palavras para resolução. Por isso, conta com utilização de bibliotecas prontas. Foi utilizado, também, o conceito de similaridade de cossenos para construção das relações entre palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das Bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Activation, Input, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Base Text - Matrix Representation.txt')                               # Abre o arquivo\n",
    "\n",
    "raw_data = f.read()                                                             # Le o arquivo\n",
    "f.close()                                                                       # Fecha o arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fusce risus ex, posuere at ante at, condimentum vestibulum nunc. Proin dapibus egestas neque, a tempor odio pharetra eget. Nullam tempus felis eu consectetur tincidunt. Integer fermentum eu quam vitae tempus. Vivamus volutpat ut dui vitae sollicitudin. Donec ornare dolor a vestibulum pharetra. Mauris eget dui sapien. Mauris lobortis feugiat neque, nec congue leo viverra semper. In vel mauris nunc. Aenean scelerisque arcu a varius tempor. Proin quis nisi et mi dictum tempor. Pellentesque mattis risus metus, id luctus orci ultrices ac. Praesent bibendum lectus a nisl mollis, eu suscipit eros pretium.\\nPhasellus vitae elit efficitur, varius felis id, vulputate neque. Praesent dictum nunc in velit lobortis tempus. Duis pulvinar ut urna eget volutpat. In hac habitasse platea dictumst. Aenean eros libero, ultrices eu dolor id, ultrices bibendum mauris. Nunc quis nunc feugiat, dapibus sem eget, pretium orci. Mauris mauris felis, pulvinar nec dapibus in, laoreet ac nibh. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. In sed scelerisque massa. Morbi sit amet ex erat. Duis sit amet laoreet ipsum. Nullam rutrum dapibus metus id sollicitudin. Sed lorem metus, maximus id maximus ac, vehicula vitae neque.\\nCurabitur vestibulum lorem diam, nec dictum lectus sodales id. Morbi at dui at ex fermentum porttitor sit amet et ipsum. Nullam et nibh vitae arcu porta pretium. Aenean ultricies bibendum nibh vitae mattis. Donec nec dignissim lorem. Vivamus ut lectus nec sem suscipit gravida. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Proin nec metus at sapien tempor ultrices. Donec sed orci ante. Quisque finibus maximus justo, sit amet dignissim justo ornare ut. Morbi imperdiet sagittis tristique. Nunc vestibulum velit eget neque ultrices, sit amet egestas elit eleifend.\\nCurabitur facilisis elementum ligula vitae pellentesque. Nulla facilisi. Nulla vel tristique arcu. Sed dictum nisl ac laoreet venenatis. Proin eros est, suscipit id sodales eu, semper maximus eros. Sed maximus id nulla vel auctor. Nullam libero odio, auctor eget felis et, viverra gravida nisl. Vivamus sed luctus eros, nec mattis leo. Phasellus eget accumsan justo. Proin nisl sem, luctus ut gravida consequat, congue sit amet arcu.\\n\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing dos dados --> .lower() + re.sub() [subtituir expressões regulares] + Removendo as Stopwords [palavras não relevantes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed = raw_data.lower()\n",
    "data_processed = re.sub('[^A-Za-z]+', ' ', data_processed)\n",
    "data_processed = data_processed.split()\n",
    "\n",
    "data_processed.remove('at')\n",
    "data_processed.remove('a')\n",
    "data_processed = np.array(data_processed)\n",
    "data_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrescendo dados únicos ao vocabulário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142,), (142,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary, counts = np.unique(data_processed, return_counts=True)\n",
    "\n",
    "vocabulary.shape, counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprementando vetor encoder para pré-processamento das features categóricas em um modelo ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 142)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_one_hot_vector(word):\n",
    "\n",
    "    vec = np.zeros((vocabulary.shape[0], ))\n",
    "\n",
    "    index = (vocabulary == word).argmax()\n",
    "\n",
    "    vec[index] = 1\n",
    "\n",
    "    return vec\n",
    "#-------------------------------------------------------------------#\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for word in data_processed:\n",
    "\n",
    "    dataset.append(get_one_hot_vector(word))\n",
    "\n",
    "dataset = np.asarray(dataset)\n",
    "#-------------------------------------------------------------------#\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando em Train e Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (284,) (347, 284)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((dataset.shape[0]-1, dataset.shape[1]*2))              # Bigram\n",
    "#-------------------------------------------------------------------#\n",
    "for i in range(X.shape[0]-1):\n",
    "\n",
    "    X[i] = np.hstack((dataset[i], dataset[i+1]))\n",
    "#-------------------------------------------------------------------#\n",
    "\n",
    "print(X[0], X[0].shape, X.shape)\n",
    "#-------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((347, 284), (347, 142))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset[1:]\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((277, 284), (70, 284), (277, 142), (70, 142))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------#\n",
    "split = int(0.80 * X.shape[0])                                      # --> Relação 80:20\n",
    "\n",
    "X_train = X[:split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "#-------------------------------------------------------------------#\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando Word embeddings usando Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 284)]             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 300)               85500     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 142)               42742     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,242\n",
      "Trainable params: 128,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding = 300\n",
    "#-------------------------------------------------------------------#\n",
    "inp = Input(shape=(284,))\n",
    "\n",
    "emb = Dense(embedding, activation='tanh')(inp)\n",
    "emb = Dropout(0.4)(emb)\n",
    "\n",
    "out = Dense(142, activation='softmax')(emb)\n",
    "#-------------------------------------------------------------------#\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#-------------------------------------------------------------------#\n",
    "\n",
    "encoder = Model(inputs=inp, outputs=emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.9674 - accuracy: 0.0108 - val_loss: 4.9432 - val_accuracy: 0.0143\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.9233 - accuracy: 0.0072 - val_loss: 4.9234 - val_accuracy: 0.0143\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.8899 - accuracy: 0.0361 - val_loss: 4.9034 - val_accuracy: 0.0143\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8461 - accuracy: 0.0578 - val_loss: 4.8832 - val_accuracy: 0.0571\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8132 - accuracy: 0.1047 - val_loss: 4.8630 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7618 - accuracy: 0.1516 - val_loss: 4.8428 - val_accuracy: 0.1571\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.7393 - accuracy: 0.2202 - val_loss: 4.8226 - val_accuracy: 0.1714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6901 - accuracy: 0.3213 - val_loss: 4.8024 - val_accuracy: 0.2429\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6529 - accuracy: 0.4368 - val_loss: 4.7822 - val_accuracy: 0.3143\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.6062 - accuracy: 0.6101 - val_loss: 4.7620 - val_accuracy: 0.3571\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5698 - accuracy: 0.6354 - val_loss: 4.7417 - val_accuracy: 0.4143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.5319 - accuracy: 0.7329 - val_loss: 4.7215 - val_accuracy: 0.4714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.5033 - accuracy: 0.8051 - val_loss: 4.7013 - val_accuracy: 0.4857\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.4453 - accuracy: 0.8700 - val_loss: 4.6811 - val_accuracy: 0.5143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4131 - accuracy: 0.8989 - val_loss: 4.6608 - val_accuracy: 0.5286\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3602 - accuracy: 0.9242 - val_loss: 4.6404 - val_accuracy: 0.5571\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.3251 - accuracy: 0.9603 - val_loss: 4.6200 - val_accuracy: 0.5857\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.2930 - accuracy: 0.9819 - val_loss: 4.5996 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2411 - accuracy: 0.9856 - val_loss: 4.5790 - val_accuracy: 0.6143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2003 - accuracy: 0.9892 - val_loss: 4.5585 - val_accuracy: 0.6143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1706 - accuracy: 0.9964 - val_loss: 4.5378 - val_accuracy: 0.6143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.1160 - accuracy: 0.9928 - val_loss: 4.5170 - val_accuracy: 0.6143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4.0829 - accuracy: 0.9964 - val_loss: 4.4962 - val_accuracy: 0.6286\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0298 - accuracy: 1.0000 - val_loss: 4.4752 - val_accuracy: 0.6429\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9820 - accuracy: 0.9928 - val_loss: 4.4542 - val_accuracy: 0.6429\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9469 - accuracy: 0.9964 - val_loss: 4.4330 - val_accuracy: 0.6429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8884 - accuracy: 1.0000 - val_loss: 4.4117 - val_accuracy: 0.6429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.8396 - accuracy: 1.0000 - val_loss: 4.3904 - val_accuracy: 0.6429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8133 - accuracy: 1.0000 - val_loss: 4.3688 - val_accuracy: 0.6429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7524 - accuracy: 1.0000 - val_loss: 4.3472 - val_accuracy: 0.6429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7070 - accuracy: 1.0000 - val_loss: 4.3254 - val_accuracy: 0.6286\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6680 - accuracy: 1.0000 - val_loss: 4.3035 - val_accuracy: 0.6286\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.6155 - accuracy: 1.0000 - val_loss: 4.2815 - val_accuracy: 0.6286\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.5759 - accuracy: 1.0000 - val_loss: 4.2593 - val_accuracy: 0.6286\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.5121 - accuracy: 1.0000 - val_loss: 4.2369 - val_accuracy: 0.6286\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4816 - accuracy: 1.0000 - val_loss: 4.2145 - val_accuracy: 0.6571\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4153 - accuracy: 1.0000 - val_loss: 4.1918 - val_accuracy: 0.6571\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3838 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.6571\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3305 - accuracy: 1.0000 - val_loss: 4.1461 - val_accuracy: 0.6571\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2671 - accuracy: 1.0000 - val_loss: 4.1229 - val_accuracy: 0.6571\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2154 - accuracy: 1.0000 - val_loss: 4.0997 - val_accuracy: 0.6571\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1679 - accuracy: 1.0000 - val_loss: 4.0762 - val_accuracy: 0.6571\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1190 - accuracy: 1.0000 - val_loss: 4.0527 - val_accuracy: 0.6571\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.0584 - accuracy: 1.0000 - val_loss: 4.0289 - val_accuracy: 0.6571\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.9991 - accuracy: 1.0000 - val_loss: 4.0051 - val_accuracy: 0.6571\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.9608 - accuracy: 1.0000 - val_loss: 3.9811 - val_accuracy: 0.6571\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8920 - accuracy: 1.0000 - val_loss: 3.9569 - val_accuracy: 0.6571\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.8315 - accuracy: 1.0000 - val_loss: 3.9326 - val_accuracy: 0.6571\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.7931 - accuracy: 1.0000 - val_loss: 3.9082 - val_accuracy: 0.6571\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7364 - accuracy: 1.0000 - val_loss: 3.8836 - val_accuracy: 0.6571\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.6904 - accuracy: 1.0000 - val_loss: 3.8590 - val_accuracy: 0.6571\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6103 - accuracy: 1.0000 - val_loss: 3.8342 - val_accuracy: 0.6286\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5499 - accuracy: 1.0000 - val_loss: 3.8094 - val_accuracy: 0.6286\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5018 - accuracy: 1.0000 - val_loss: 3.7845 - val_accuracy: 0.6286\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4404 - accuracy: 1.0000 - val_loss: 3.7595 - val_accuracy: 0.6286\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.3800 - accuracy: 1.0000 - val_loss: 3.7343 - val_accuracy: 0.6286\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.3213 - accuracy: 1.0000 - val_loss: 3.7090 - val_accuracy: 0.6286\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.2653 - accuracy: 1.0000 - val_loss: 3.6837 - val_accuracy: 0.6286\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2219 - accuracy: 1.0000 - val_loss: 3.6583 - val_accuracy: 0.6286\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.1394 - accuracy: 1.0000 - val_loss: 3.6328 - val_accuracy: 0.6286\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.0784 - accuracy: 1.0000 - val_loss: 3.6074 - val_accuracy: 0.6286\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.0240 - accuracy: 1.0000 - val_loss: 3.5819 - val_accuracy: 0.6286\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.9757 - accuracy: 1.0000 - val_loss: 3.5564 - val_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.9322 - accuracy: 1.0000 - val_loss: 3.5309 - val_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8722 - accuracy: 1.0000 - val_loss: 3.5053 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.8118 - accuracy: 1.0000 - val_loss: 3.4797 - val_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7492 - accuracy: 1.0000 - val_loss: 3.4541 - val_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6893 - accuracy: 1.0000 - val_loss: 3.4285 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6263 - accuracy: 1.0000 - val_loss: 3.4028 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5840 - accuracy: 1.0000 - val_loss: 3.3771 - val_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5172 - accuracy: 1.0000 - val_loss: 3.3514 - val_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4900 - accuracy: 1.0000 - val_loss: 3.3257 - val_accuracy: 0.6143\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4259 - accuracy: 1.0000 - val_loss: 3.3000 - val_accuracy: 0.6143\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3553 - accuracy: 1.0000 - val_loss: 3.2743 - val_accuracy: 0.6143\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3352 - accuracy: 1.0000 - val_loss: 3.2485 - val_accuracy: 0.6143\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2830 - accuracy: 1.0000 - val_loss: 3.2228 - val_accuracy: 0.6143\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2349 - accuracy: 1.0000 - val_loss: 3.1971 - val_accuracy: 0.6286\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1926 - accuracy: 1.0000 - val_loss: 3.1714 - val_accuracy: 0.6286\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1112 - accuracy: 1.0000 - val_loss: 3.1458 - val_accuracy: 0.6286\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0885 - accuracy: 1.0000 - val_loss: 3.1201 - val_accuracy: 0.6286\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0470 - accuracy: 1.0000 - val_loss: 3.0945 - val_accuracy: 0.6286\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9903 - accuracy: 1.0000 - val_loss: 3.0689 - val_accuracy: 0.6286\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9591 - accuracy: 1.0000 - val_loss: 3.0435 - val_accuracy: 0.6286\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9209 - accuracy: 1.0000 - val_loss: 3.0181 - val_accuracy: 0.6286\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8844 - accuracy: 1.0000 - val_loss: 2.9928 - val_accuracy: 0.6429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8352 - accuracy: 1.0000 - val_loss: 2.9677 - val_accuracy: 0.6571\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8276 - accuracy: 1.0000 - val_loss: 2.9427 - val_accuracy: 0.6571\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7652 - accuracy: 1.0000 - val_loss: 2.9179 - val_accuracy: 0.6571\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7554 - accuracy: 1.0000 - val_loss: 2.8934 - val_accuracy: 0.6571\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7141 - accuracy: 1.0000 - val_loss: 2.8690 - val_accuracy: 0.6571\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6632 - accuracy: 1.0000 - val_loss: 2.8448 - val_accuracy: 0.6714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6545 - accuracy: 1.0000 - val_loss: 2.8209 - val_accuracy: 0.6714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6201 - accuracy: 1.0000 - val_loss: 2.7972 - val_accuracy: 0.6857\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5975 - accuracy: 1.0000 - val_loss: 2.7738 - val_accuracy: 0.7000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5515 - accuracy: 1.0000 - val_loss: 2.7506 - val_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5420 - accuracy: 1.0000 - val_loss: 2.7278 - val_accuracy: 0.7000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5069 - accuracy: 1.0000 - val_loss: 2.7052 - val_accuracy: 0.7000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4779 - accuracy: 1.0000 - val_loss: 2.6830 - val_accuracy: 0.7000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4681 - accuracy: 1.0000 - val_loss: 2.6612 - val_accuracy: 0.7143\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4488 - accuracy: 1.0000 - val_loss: 2.6397 - val_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                epochs=100,\n",
    "                shuffle=False,\n",
    "                batch_size=1024,\n",
    "                validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficamente, temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------#\n",
    "# Gráfico do Erro:\n",
    "plt.figure()\n",
    "plt.plot(hist.history['loss'], 'b')\n",
    "plt.plot(hist.history['val_loss'], 'g')\n",
    "plt.show()\n",
    "#-------------------------------------------------------------------#\n",
    "# Gráfico da Acurácia:\n",
    "plt.figure()\n",
    "plt.plot(hist.history['accuracy'], 'b')\n",
    "plt.plot(hist.history['val_accuracy'], 'g')\n",
    "plt.show()\n",
    "#-------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevendo Similaridades --> Cosine Similarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "a = encoder.predict(X)\n",
    "w2v = {}\n",
    "alpha = 0.9\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "\n",
    "    try:\n",
    "        old_vec = w2v[vocabulary[y[i].argmax()]]\n",
    "        new_vec = alpha*old_vec + (1-alpha)*a[i] # Running Average\n",
    "        w2v[vocabulary[y[i].argmax()]] = new_vec\n",
    "\n",
    "    except:\n",
    "        w2v[vocabulary[y[i].argmax()]] = a[i]\n",
    "\n",
    "print (len(w2v.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16817178\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2)/np.sqrt((v1**2).sum()*(v2**2).sum())\n",
    "\n",
    "v1 = w2v['tempus']\n",
    "v2 = w2v['ultrices']\n",
    "\n",
    "print(cosine_similarity(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix = pd.DataFrame(w2v, columns=w2v.keys())\n",
    "matrix['Palavra'] = data_processed[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risus</th>\n",
       "      <th>ex</th>\n",
       "      <th>posuere</th>\n",
       "      <th>ante</th>\n",
       "      <th>at</th>\n",
       "      <th>condimentum</th>\n",
       "      <th>vestibulum</th>\n",
       "      <th>nunc</th>\n",
       "      <th>proin</th>\n",
       "      <th>dapibus</th>\n",
       "      <th>...</th>\n",
       "      <th>elementum</th>\n",
       "      <th>ligula</th>\n",
       "      <th>nulla</th>\n",
       "      <th>facilisi</th>\n",
       "      <th>venenatis</th>\n",
       "      <th>est</th>\n",
       "      <th>auctor</th>\n",
       "      <th>accumsan</th>\n",
       "      <th>consequat</th>\n",
       "      <th>Palavra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.217701</td>\n",
       "      <td>-0.159472</td>\n",
       "      <td>-0.250682</td>\n",
       "      <td>-0.205301</td>\n",
       "      <td>0.052902</td>\n",
       "      <td>0.149924</td>\n",
       "      <td>-0.122299</td>\n",
       "      <td>0.031278</td>\n",
       "      <td>-0.187790</td>\n",
       "      <td>0.109891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046554</td>\n",
       "      <td>-0.060522</td>\n",
       "      <td>-0.068479</td>\n",
       "      <td>0.103068</td>\n",
       "      <td>-0.124483</td>\n",
       "      <td>-0.042701</td>\n",
       "      <td>-0.102535</td>\n",
       "      <td>-0.116946</td>\n",
       "      <td>-0.090302</td>\n",
       "      <td>fusce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080065</td>\n",
       "      <td>-0.219400</td>\n",
       "      <td>0.097379</td>\n",
       "      <td>0.198382</td>\n",
       "      <td>-0.120515</td>\n",
       "      <td>-0.277028</td>\n",
       "      <td>0.220183</td>\n",
       "      <td>-0.015249</td>\n",
       "      <td>0.107477</td>\n",
       "      <td>-0.152376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221892</td>\n",
       "      <td>-0.047072</td>\n",
       "      <td>-0.075878</td>\n",
       "      <td>-0.150789</td>\n",
       "      <td>-0.076866</td>\n",
       "      <td>0.029445</td>\n",
       "      <td>-0.150226</td>\n",
       "      <td>0.112174</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>risus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.214448</td>\n",
       "      <td>-0.035499</td>\n",
       "      <td>0.304467</td>\n",
       "      <td>-0.182306</td>\n",
       "      <td>0.289113</td>\n",
       "      <td>-0.068165</td>\n",
       "      <td>0.323386</td>\n",
       "      <td>-0.078212</td>\n",
       "      <td>0.202903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176725</td>\n",
       "      <td>0.157032</td>\n",
       "      <td>0.055280</td>\n",
       "      <td>0.141677</td>\n",
       "      <td>-0.072056</td>\n",
       "      <td>0.147388</td>\n",
       "      <td>0.137222</td>\n",
       "      <td>0.179712</td>\n",
       "      <td>0.112323</td>\n",
       "      <td>ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.031549</td>\n",
       "      <td>-0.062066</td>\n",
       "      <td>0.155259</td>\n",
       "      <td>-0.049042</td>\n",
       "      <td>-0.204496</td>\n",
       "      <td>0.200769</td>\n",
       "      <td>0.038880</td>\n",
       "      <td>0.192922</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098756</td>\n",
       "      <td>-0.031380</td>\n",
       "      <td>0.053736</td>\n",
       "      <td>-0.094499</td>\n",
       "      <td>-0.067921</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>0.021669</td>\n",
       "      <td>-0.113992</td>\n",
       "      <td>-0.021905</td>\n",
       "      <td>posuere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.120359</td>\n",
       "      <td>-0.026617</td>\n",
       "      <td>-0.244318</td>\n",
       "      <td>-0.223593</td>\n",
       "      <td>0.052878</td>\n",
       "      <td>0.145789</td>\n",
       "      <td>-0.035685</td>\n",
       "      <td>-0.169227</td>\n",
       "      <td>-0.043155</td>\n",
       "      <td>0.204876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076213</td>\n",
       "      <td>-0.142274</td>\n",
       "      <td>-0.039122</td>\n",
       "      <td>-0.082780</td>\n",
       "      <td>0.074759</td>\n",
       "      <td>-0.097207</td>\n",
       "      <td>-0.158709</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>-0.248815</td>\n",
       "      <td>ante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.222407</td>\n",
       "      <td>-0.077976</td>\n",
       "      <td>-0.047438</td>\n",
       "      <td>0.304928</td>\n",
       "      <td>0.126895</td>\n",
       "      <td>-0.148688</td>\n",
       "      <td>0.228169</td>\n",
       "      <td>-0.136961</td>\n",
       "      <td>0.178631</td>\n",
       "      <td>-0.159565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234887</td>\n",
       "      <td>0.070960</td>\n",
       "      <td>0.228182</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.023841</td>\n",
       "      <td>0.064362</td>\n",
       "      <td>0.217623</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>-0.110914</td>\n",
       "      <td>dictum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.252468</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.267248</td>\n",
       "      <td>0.255549</td>\n",
       "      <td>0.235776</td>\n",
       "      <td>0.336945</td>\n",
       "      <td>0.324843</td>\n",
       "      <td>0.171410</td>\n",
       "      <td>-0.090244</td>\n",
       "      <td>0.137644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.005279</td>\n",
       "      <td>0.137153</td>\n",
       "      <td>0.126048</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>0.300786</td>\n",
       "      <td>0.042684</td>\n",
       "      <td>0.157886</td>\n",
       "      <td>0.039040</td>\n",
       "      <td>nisl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.072433</td>\n",
       "      <td>0.175060</td>\n",
       "      <td>0.274087</td>\n",
       "      <td>-0.015439</td>\n",
       "      <td>0.204228</td>\n",
       "      <td>0.090292</td>\n",
       "      <td>0.203240</td>\n",
       "      <td>0.123719</td>\n",
       "      <td>0.235701</td>\n",
       "      <td>0.231166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>0.039705</td>\n",
       "      <td>-0.093394</td>\n",
       "      <td>0.065032</td>\n",
       "      <td>0.025788</td>\n",
       "      <td>0.106675</td>\n",
       "      <td>-0.135897</td>\n",
       "      <td>-0.115910</td>\n",
       "      <td>0.118365</td>\n",
       "      <td>ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.061475</td>\n",
       "      <td>0.020652</td>\n",
       "      <td>0.226420</td>\n",
       "      <td>0.353305</td>\n",
       "      <td>-0.166236</td>\n",
       "      <td>0.173138</td>\n",
       "      <td>-0.055716</td>\n",
       "      <td>0.320926</td>\n",
       "      <td>0.172914</td>\n",
       "      <td>0.146220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116439</td>\n",
       "      <td>0.115180</td>\n",
       "      <td>-0.022259</td>\n",
       "      <td>-0.017991</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>-0.047204</td>\n",
       "      <td>0.091187</td>\n",
       "      <td>-0.084058</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>laoreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.300470</td>\n",
       "      <td>-0.080154</td>\n",
       "      <td>-0.080363</td>\n",
       "      <td>-0.185025</td>\n",
       "      <td>-0.159543</td>\n",
       "      <td>0.354535</td>\n",
       "      <td>0.094371</td>\n",
       "      <td>0.252676</td>\n",
       "      <td>-0.033127</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.080332</td>\n",
       "      <td>-0.084839</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>-0.099250</td>\n",
       "      <td>0.044511</td>\n",
       "      <td>0.080568</td>\n",
       "      <td>0.264204</td>\n",
       "      <td>0.080038</td>\n",
       "      <td>venenatis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        risus        ex   posuere      ante        at  condimentum  \\\n",
       "0   -0.217701 -0.159472 -0.250682 -0.205301  0.052902     0.149924   \n",
       "1    0.080065 -0.219400  0.097379  0.198382 -0.120515    -0.277028   \n",
       "2    0.007903  0.214448 -0.035499  0.304467 -0.182306     0.289113   \n",
       "3   -0.031549 -0.062066  0.155259 -0.049042 -0.204496     0.200769   \n",
       "4   -0.120359 -0.026617 -0.244318 -0.223593  0.052878     0.145789   \n",
       "..        ...       ...       ...       ...       ...          ...   \n",
       "295  0.222407 -0.077976 -0.047438  0.304928  0.126895    -0.148688   \n",
       "296 -0.252468  0.238267  0.267248  0.255549  0.235776     0.336945   \n",
       "297 -0.072433  0.175060  0.274087 -0.015439  0.204228     0.090292   \n",
       "298  0.061475  0.020652  0.226420  0.353305 -0.166236     0.173138   \n",
       "299  0.300470 -0.080154 -0.080363 -0.185025 -0.159543     0.354535   \n",
       "\n",
       "     vestibulum      nunc     proin   dapibus  ...  elementum    ligula  \\\n",
       "0     -0.122299  0.031278 -0.187790  0.109891  ...   0.046554 -0.060522   \n",
       "1      0.220183 -0.015249  0.107477 -0.152376  ...  -0.221892 -0.047072   \n",
       "2     -0.068165  0.323386 -0.078212  0.202903  ...   0.176725  0.157032   \n",
       "3      0.038880  0.192922  0.097672  0.110132  ...  -0.098756 -0.031380   \n",
       "4     -0.035685 -0.169227 -0.043155  0.204876  ...  -0.076213 -0.142274   \n",
       "..          ...       ...       ...       ...  ...        ...       ...   \n",
       "295    0.228169 -0.136961  0.178631 -0.159565  ...   0.234887  0.070960   \n",
       "296    0.324843  0.171410 -0.090244  0.137644  ...  -0.002314 -0.005279   \n",
       "297    0.203240  0.123719  0.235701  0.231166  ...  -0.011741  0.039705   \n",
       "298   -0.055716  0.320926  0.172914  0.146220  ...  -0.116439  0.115180   \n",
       "299    0.094371  0.252676 -0.033127  0.211200  ...  -0.003060 -0.080332   \n",
       "\n",
       "        nulla  facilisi  venenatis       est    auctor  accumsan  consequat  \\\n",
       "0   -0.068479  0.103068  -0.124483 -0.042701 -0.102535 -0.116946  -0.090302   \n",
       "1   -0.075878 -0.150789  -0.076866  0.029445 -0.150226  0.112174   0.030505   \n",
       "2    0.055280  0.141677  -0.072056  0.147388  0.137222  0.179712   0.112323   \n",
       "3    0.053736 -0.094499  -0.067921 -0.004354  0.021669 -0.113992  -0.021905   \n",
       "4   -0.039122 -0.082780   0.074759 -0.097207 -0.158709  0.032073  -0.248815   \n",
       "..        ...       ...        ...       ...       ...       ...        ...   \n",
       "295  0.228182  0.007013   0.023841  0.064362  0.217623  0.040580  -0.110914   \n",
       "296  0.137153  0.126048   0.128069  0.300786  0.042684  0.157886   0.039040   \n",
       "297 -0.093394  0.065032   0.025788  0.106675 -0.135897 -0.115910   0.118365   \n",
       "298 -0.022259 -0.017991   0.032119 -0.047204  0.091187 -0.084058   0.024632   \n",
       "299 -0.084839  0.038330  -0.099250  0.044511  0.080568  0.264204   0.080038   \n",
       "\n",
       "       Palavra  \n",
       "0        fusce  \n",
       "1        risus  \n",
       "2           ex  \n",
       "3      posuere  \n",
       "4         ante  \n",
       "..         ...  \n",
       "295     dictum  \n",
       "296       nisl  \n",
       "297         ac  \n",
       "298    laoreet  \n",
       "299  venenatis  \n",
       "\n",
       "[300 rows x 142 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df6438d9c6021a8537ed1f8dc3c8c872338752a98d8cf1a180ae921c1efc4c46"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
